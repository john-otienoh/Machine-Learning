{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b6abf3",
   "metadata": {},
   "source": [
    "**Quantitative data** is the measurement of somethingâ€”whether class size, monthly sales, or student scores. The natural way to represent these quantities is numerically (e.g., 29 students, $529,392 in sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afb2b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bcb11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "features = np.array([[0.5, 0.5],[1.1, 3.4],[1.5, 20.2],[1.63, 34.4],[10.9, 3.3]])\n",
    "matrix = np.array([[2, 3],[2, 3],[2, 3]])\n",
    "age = np.array([[6],[12],[20],[36],[65]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13042c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.05769231, 0.08554572],\n",
       "       [0.09615385, 0.58112094],\n",
       "       [0.10865385, 1.        ],\n",
       "       [1.        , 0.08259587]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rescaling a feature\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_feature = minmax_scale.fit_transform(features)\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2bbe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0\n",
      "Standard deviation: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.67215216, -0.90948567],\n",
       "       [-0.51857589, -0.68709879],\n",
       "       [-0.4161917 ,  0.60121144],\n",
       "       [-0.38291684,  1.69014032],\n",
       "       [ 1.9898366 , -0.6947673 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing a Feature\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized = scaler.fit_transform(features)\n",
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f2595f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.88679245e+00, -1.71597633e-01],\n",
       "       [-7.54716981e-01,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  9.94082840e-01],\n",
       "       [ 2.45283019e-01,  1.83431953e+00],\n",
       "       [ 1.77358491e+01, -5.91715976e-03]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If our data has significant outliers.\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "# Transform feature\n",
    "robust_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the first observation's values: 1.414213562373095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing Observations\n",
    "features_l2_norm = preprocessing.Normalizer(norm=\"l2\").transform(features)\n",
    "features_l1_norm = preprocessing.Normalizer(norm=\"l1\").transform(features)\n",
    "print(\"Sum of the first observation\\'s values:\",features_l1_norm[0, 0] + features_l1_norm[0, 1])\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b19d4ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5  ,  0.5  ,  0.25 ],\n",
       "       [ 1.1  ,  3.4  ,  3.74 ],\n",
       "       [ 1.5  , 20.2  , 30.3  ],\n",
       "       [ 1.63 , 34.4  , 56.072],\n",
       "       [10.9  ,  3.3  , 35.97 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating Polynomial and Interaction Features\n",
    "polynomial_interaction = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "polynomial_interaction.fit_transform(features)\n",
    "# Restrict only interaction features\n",
    "interaction = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f26d4559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming Features\n",
    "def add_ten(x: int) -> int:\n",
    "    return x+10\n",
    "\n",
    "ten_transformer = preprocessing.FunctionTransformer(add_ten)\n",
    "ten_transformer.transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a437bb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detecting Outliers\n",
    "# 1. assume the data is normally distributed\n",
    "simulated_features, _ = make_blobs(\n",
    "    n_samples=10, n_features=2, centers=1, random_state=1\n",
    ")\n",
    "simulated_features[0,0], simulated_features[0,1] = 1000, 1000\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "outlier_detector.fit(simulated_features)\n",
    "outlier_detector.predict(simulated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "563af02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using IQR\n",
    "feature = simulated_features[:,0]\n",
    "def indices_of_outliers(x: int) -> np.array(int):\n",
    "    q1,q3 = np.percentile(x, [25,75])\n",
    "    iqr = q3-q1\n",
    "    lower_bound = q1 - (iqr*1.5)\n",
    "    upper_bound = q3 + (iqr*1.5)\n",
    "    return np.where((x>upper_bound) | (x<lower_bound))\n",
    "\n",
    "indices_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16fa159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>Not Outlier</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>Not Outlier</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>Not Outlier</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet      Outlier  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500  Not Outlier            7.313220\n",
       "1   392333        3.5         2500  Not Outlier            7.824046\n",
       "2   293222        2.0         1500  Not Outlier            7.313220\n",
       "3  4322032      116.0        48000      Outlier           10.778956"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling Outliers\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "houses['Outlier'] = np.where(houses['Bathrooms'] < 20, \"Not Outlier\", \"Outlier\")\n",
    "# Log Feature\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses['Square_Feet']]\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949909e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discretizating Features\n",
    "binarizer = preprocessing.Binarizer(threshold=18)\n",
    "# Two bins\n",
    "binarizer.fit_transform(age)\n",
    "# Multiple bins\n",
    "np.digitize(age, bins=[20,30,64])\n",
    "np.digitize(age, bins=[20,30,64], right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3935d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Features 2</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Features 2  Group\n",
       "0  -9.877554   -3.336145      2\n",
       "1  -7.287210   -8.353986      0\n",
       "2  -6.943061   -7.023744      0\n",
       "3  -7.440167   -8.791959      0\n",
       "4  -6.641388   -8.075888      0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping Observations Using Clustering\n",
    "blob_features, _ = make_blobs(\n",
    "    n_samples = 50,n_features = 2,centers = 3,random_state = 1\n",
    ")\n",
    "df = pd.DataFrame(blob_features, columns=[\"Feature 1\", \"Features 2\"])\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "clusterer.fit(blob_features)\n",
    "df['Group'] = clusterer.predict(blob_features)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Observations with Missing Values\n",
    "# Keep only observations that are not (denoted by ~) missing\n",
    "features[~np.isnan(features).any(axis=1)]\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c2255d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: 1.0959262913919632\n"
     ]
    }
   ],
   "source": [
    "# Imputing Missing Values\n",
    "impute_features, _ = make_blobs(\n",
    "    n_samples = 1000,n_features = 2,random_state = 1\n",
    ")\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standardized_features = scaler.fit_transform(impute_features)\n",
    "\n",
    "# Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "\n",
    "# Predict the missing values in the feature matrix\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "features_knn_imputed = knn_imputer.fit_transform(standardized_features)\n",
    "\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9466dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Using SimpleImputer\n",
    "# Create imputer using the \"mean\" strategy\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "# Impute values\n",
    "features_mean_imputed = mean_imputer.fit_transform(features)\n",
    "# Compare true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_mean_imputed[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
